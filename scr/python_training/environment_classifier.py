# -*- coding: utf-8 -*-
"""Environment_Classifier.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DkBzRKeoFeB5tlokQ21bOvWxtnZHsr6Q
"""

import numpy as np

# ---------- 1. Training data ----------
# Input dataset: [Temperature, Light, VOC, Pressure]
X = np.array([
    # Normal (0)
    [25, 300, 150, 1010],
    [24, 280, 160, 1008],
    [26, 320, 140, 1011],

    # Humid (1)
    [23, 270, 200, 1005],
    [22, 260, 210, 1004],
    [24, 275, 190, 1006],

    # Overheated (2)
    [35, 400, 180, 1009],
    [34, 390, 175, 1008],
    [36, 420, 185, 1010],

    # Poor Air (3)
    [28, 300, 600, 1012],
    [27, 290, 650, 1011],
    [29, 310, 580, 1010],

    # Low Light (4)
    [24, 30, 140, 1008],
    [23, 20, 130, 1010],
    [25, 40, 135, 1009],
])

# ---------- Output labels ----------
Y = np.array([
    [1,0,0,0,0], [1,0,0,0,0], [1,0,0,0,0],   # Normal
    [0,1,0,0,0], [0,1,0,0,0], [0,1,0,0,0],   # Humid
    [0,0,1,0,0], [0,0,1,0,0], [0,0,1,0,0],   # Overheated
    [0,0,0,1,0], [0,0,0,1,0], [0,0,0,1,0],   # Poor Air
    [0,0,0,0,1], [0,0,0,0,1], [0,0,0,0,1],   # Low Light
])

# ---------- 2. Normalize inputs 0–1 ----------
X = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))

# ---------- 3. Initialize weights ----------
np.random.seed(0)
hidden_neurons = 8

W1 = np.random.randn(4, hidden_neurons) * 0.5
b1 = np.zeros((1, hidden_neurons))

W2 = np.random.randn(hidden_neurons, 5) * 0.5
b2 = np.zeros((1, 5))

# ---------- 4. Hyperparameters ----------
learning_rate = 0.05
epochs = 5000

# ---------- 5. Activation ----------
def leaky_relu(x):
    return np.where(x > 0, x, 0.01*x)

def leaky_relu_derivative(x):
    dx = np.ones_like(x)
    dx[x < 0] = 0.01
    return dx

# ---------- 6. Training loop ----------
for epoch in range(epochs):
    H = leaky_relu(np.dot(X, W1) + b1)
    Y_pred = leaky_relu(np.dot(H, W2) + b2)

    error = Y_pred - Y
    loss = np.mean(error**2)

    dY = error * leaky_relu_derivative(Y_pred)
    dW2 = np.dot(H.T, dY)
    db2 = np.sum(dY, axis=0, keepdims=True)

    dH = np.dot(dY, W2.T) * leaky_relu_derivative(H)
    dW1 = np.dot(X.T, dH)
    db1 = np.sum(dH, axis=0, keepdims=True)

    W2 -= learning_rate * dW2
    b2 -= learning_rate * db2
    W1 -= learning_rate * dW1
    b1 -= learning_rate * db1

    if epoch % 500 == 0:
        print(f"Epoch {epoch}, Loss: {loss:.4f}")

# ---------- 7. Test ----------
H_test = leaky_relu(np.dot(X, W1) + b1)
Y_test = leaky_relu(np.dot(H_test, W2) + b2)
predictions = np.argmax(Y_test, axis=1)

print("\nPredicted classes:\n", predictions)

# ============================================================
# 8. QUANTIZATION FOR FPGA (SIGNED 16-BIT: Q1.15)
# ============================================================

scale = 32768  # Q1.15 scaling factor

W1_int = np.clip(np.round(W1 * scale), -32768, 32767).astype(np.int16)
b1_int = np.clip(np.round(b1 * scale), -32768, 32767).astype(np.int16)

W2_int = np.clip(np.round(W2 * scale), -32768, 32767).astype(np.int16)
b2_int = np.clip(np.round(b2 * scale), -32768, 32767).astype(np.int16)

print("\n===== Quantized Signed 16-bit (Q1.15) =====")
print("\nW1_int:\n", W1_int)
print("\nb1_int:\n", b1_int)
print("\nW2_int:\n", W2_int)
print("\nb2_int:\n", b2_int)

from tabulate import tabulate
import numpy as np

def print_table(matrix, title):
    print("\n================================================")
    print(title)
    print("================================================")

    # If matrix is 1D → reshape into 1×N for table printing
    if len(matrix.shape) == 1:
        matrix = matrix.reshape(1, -1)

    headers = [f"C{i}" for i in range(matrix.shape[1])]

    table = tabulate(matrix,
                     headers=headers,
                     tablefmt="fancy_grid",
                     showindex=True,
                     stralign="center",
                     numalign="center")

    print(table)


# ---------- PRINT SIGNED 16-BIT TABLES ----------
print_table(W1_int, "Hidden Layer Weights W1_int (4 × 8)")
print_table(b1_int, "Hidden Layer Biases b1_int (1 × 8)")
print_table(W2_int, "Output Layer Weights W2_int (8 × 5)")
print_table(b2_int, "Output Layer Biases b2_int (1 × 5)")